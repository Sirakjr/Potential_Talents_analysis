{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b0f622-7d13-46e9-bc55-8313bdcf5199",
   "metadata": {},
   "source": [
    "# Potential Talents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0604cbed-1cd1-4412-9bb8-484304571c4b",
   "metadata": {},
   "source": [
    "## Background:\n",
    "\n",
    "As a talent sourcing and management company, we are interested in finding talented individuals for sourcing these candidates to technology companies. Finding talented candidates is not easy, for several reasons. The first reason is one needs to understand what the role is very well to fill in that spot, this requires understanding the client’s needs and what they are looking for in a potential candidate. The second reason is one needs to understand what makes a candidate shine for the role we are in search for. Third, where to find talented individuals is another challenge.\n",
    "\n",
    "The nature of our job requires a lot of human labor and is full of manual operations. Towards automating this process we want to build a better approach that could save us time and finally help us spot potential candidates that could fit the roles we are in search for. Moreover, going beyond that for a specific role we want to fill in we are interested in developing a machine learning powered pipeline that could spot talented individuals, and rank them based on their fitness.\n",
    "\n",
    "We are right now semi-automatically sourcing a few candidates, therefore the sourcing part is not a concern at this time but we expect to first determine best matching candidates based on how fit these candidates are for a given role. We generally make these searches based on some keywords such as “full-stack software engineer”, “engineering manager” or “aspiring human resources” based on the role we are trying to fill in. These keywords might change, and you can expect that specific keywords will be provided to you.\n",
    "\n",
    "Assuming that we were able to list and rank fitting candidates, we then employ a review procedure, as each candidate needs to be reviewed and then determined how good a fit they are through manual inspection. This procedure is done manually and at the end of this manual review, we might choose not the first fitting candidate in the list but maybe the 7th candidate in the list. If that happens, we are interested in being able to re-rank the previous list based on this information. This supervisory signal is going to be supplied by starring the 7th candidate in the list. Starring one candidate actually sets this candidate as an ideal candidate for the given role. Then, we expect the list to be re-ranked each time a candidate is starred.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8544b9e8-81d2-4846-b02b-bf346050952a",
   "metadata": {},
   "source": [
    "## Data Description:\n",
    "\n",
    "The data comes from our sourcing efforts. We removed any field that could directly reveal personal details and gave a unique identifier for each candidate.\n",
    "\n",
    "Attributes:\n",
    "id : unique identifier for candidate (numeric)\n",
    "\n",
    "job_title : job title for candidate (text)\n",
    "\n",
    "location : geographical location for candidate (text)\n",
    "\n",
    "connections: number of connections candidate has, 500+ means over 500 (text)\n",
    "\n",
    "Output (desired target):\n",
    "fit - how fit the candidate is for the role? (numeric, probability between 0-1)\n",
    "\n",
    "Keywords: “Aspiring human resources” or “seeking human resources”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a6cbf-fba2-4907-8979-1840db0acefc",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "\n",
    "Predict how fit the candidate is based on their available information (variable fit)\n",
    "\n",
    "## Success Metric(s):\n",
    "\n",
    "Rank candidates based on a fitness score.\n",
    "\n",
    "Re-rank candidates when a candidate is starred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5201834-6cd8-4537-a9ca-f1e8c1fb3fa8",
   "metadata": {},
   "source": [
    "## Imports and Preprocessing\n",
    "Let's start by importing necessary libraries and packages for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6b0dbb-a31e-4777-afed-1315a17964eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sirak\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer \n",
    "import torch\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3511b85a-d33c-4a60-9bfd-08dda4772d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sirak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "except LookupError:\n",
    "    nltk.download('punkt_tab')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb6997b-e227-4425-92f3-a7bc3bcb5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Glove embeddings\n",
    "glove_path='../glove_data/glove.6B.100d.txt'\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96515ad8-d228-4acf-91db-5dffc8a9835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading fasttext embeddings\n",
    "fasttext_path = '../fasttext_data/cc.en.300.vec'\n",
    "def load_fasttext_vectors(file_path, max_words=200000):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf8', newline='\\n', errors='ignore') as f:\n",
    "        next(f)  # skip header\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= max_words:\n",
    "                break\n",
    "            parts = line.rstrip().split(' ')\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "fasttext_embeddings = load_fasttext_vectors(fasttext_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8079e54-2754-4d3c-8b2f-a061de749e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 104 candidates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's load the data\n",
    "data = pd.read_csv('../data/potential_talents_data.csv')\n",
    "print(f\"Loaded {len(data)} candidates\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c0e36-5466-499e-9c6a-67ec64b53c5c",
   "metadata": {},
   "source": [
    "Now let's start the preprocessing by creating a custom function which will convert the text to lowercase, remove punctuation and extra whitespaces, remove the stopwords, tokenize and finally lemmatize the given text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0a3970c-a961-412b-b5bb-5b8e61ba4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    #convert to lowercase\n",
    "    text=text.lower()\n",
    "\n",
    "    #remove punctuation\n",
    "    text=re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    text=re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    #Tokenize\n",
    "    tokens=word_tokenize(text)\n",
    "\n",
    "    # Create lemmatizer object\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    #remove stopwords and lemmatize\n",
    "    tokens= [lemmatizer.lemmatize(token) for token in tokens\n",
    "    if token not in set(stopwords.words('english')) ]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fbd6d3-78f7-4064-a78c-81911a18105e",
   "metadata": {},
   "source": [
    "For some additional information about our candidates we can combine the 'job_title' and 'Location' columns and use the combined column in our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4678df46-8aa3-4683-8429-bde3a34cc89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_strings = [\n",
    "        f\"{row['job_title']} {row['location']}\" if pd.notna(row['job_title']) and pd.notna(row['location']) else \"\"\n",
    "        for _, row in data.iterrows()\n",
    "    ]\n",
    "\n",
    "data['combined_string'] = combined_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9aa5124-846b-4b1e-a205-a03ea0e4900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add a new column 'combined_string_preprocessed' to our dataset by applying the preprocess_text function\n",
    "data['combined_string_preprocessed']=data['combined_string'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf68d15-a80f-4768-b3a4-2bbc3ab6f92c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_string</th>\n",
       "      <th>combined_string_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>2019 ct bauer college business graduate magna ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>native english teacher epik english program ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aspiring Human Resources Professional Raleigh-...</td>\n",
       "      <td>aspiring human resource professional raleighdu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>People Development Coordinator at Ryan Denton,...</td>\n",
       "      <td>people development coordinator ryan denton texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advisory Board Member at Celal Bayar Universit...</td>\n",
       "      <td>advisory board member celal bayar university i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     combined_string  \\\n",
       "0  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1  Native English Teacher at EPIK (English Progra...   \n",
       "2  Aspiring Human Resources Professional Raleigh-...   \n",
       "3  People Development Coordinator at Ryan Denton,...   \n",
       "4  Advisory Board Member at Celal Bayar Universit...   \n",
       "\n",
       "                        combined_string_preprocessed  \n",
       "0  2019 ct bauer college business graduate magna ...  \n",
       "1  native english teacher epik english program ko...  \n",
       "2  aspiring human resource professional raleighdu...  \n",
       "3   people development coordinator ryan denton texas  \n",
       "4  advisory board member celal bayar university i...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['combined_string', 'combined_string_preprocessed']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae3d67-4b14-45ac-8927-53787d06d0c4",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c66ed0c-0162-408c-8032-a846d7552328",
   "metadata": {},
   "source": [
    "For word embeddings we'll try a few methods and see which one works the best: Bag of Words, TF-IDF, Bert and Sbert. We'll create custom functions for each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2517c6a2-a291-4c49-b343-a39717bf77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with the Bag of Words method\n",
    "\n",
    "def bag_of_words_similarity(data, target_string):\n",
    "    #create BoW vectorizer\n",
    "    vectorizer=CountVectorizer(max_features=1000, ngram_range=(1,2))\n",
    "\n",
    "    # combine job titles with target string\n",
    "    all_texts=list(data['combined_string_preprocessed'])+[target_string]\n",
    "    bow_matrix=vectorizer.fit_transform(all_texts)\n",
    "\n",
    "    #Calculate similarity between each job title and target\n",
    "    job_title_matrix=bow_matrix[:-1] # All except last (target)\n",
    "    target_vector = bow_matrix[-1:] # Last row (target)\n",
    "\n",
    "    similarities=cosine_similarity(job_title_matrix, target_vector).flatten()\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648dd47b-6b25-4911-8086-c25b5760d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next on the list is TF-IDF\n",
    "\n",
    "def tfidf_similarity(data, target_string):\n",
    "    #create TF-IDF vectorizer\n",
    "    vectorizer=TfidfVectorizer(max_features=1000, ngram_range=(1,2))\n",
    "\n",
    "    #Combine job titles with target string\n",
    "    all_texts=list(data['combined_string_preprocessed'])+[target_string]\n",
    "    tfidf_matrix=vectorizer.fit_transform(all_texts)\n",
    "\n",
    "    # Calculate similarity between each job title and target\n",
    "    job_titles_matrix = tfidf_matrix[:-1]  # All except last (target)\n",
    "    target_vector = tfidf_matrix[-1:]  # Last row (target)\n",
    "        \n",
    "    similarities = cosine_similarity(job_titles_matrix, target_vector).flatten()\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63fb641d-10a0-44b4-9681-14e34c4bfde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try the Glove embedding method\n",
    "def glove_similarity(data, target_string):\n",
    "\n",
    "    # First, we need a function for embedding each row by averaging word vectors\n",
    "    def get_document_embedding(text): \n",
    "        if pd.isna(text) or text == \"\":\n",
    "            return np.zeros(100)\n",
    "            \n",
    "        # Preprocess text\n",
    "        text_processed = preprocess_text(text)\n",
    "        words = text_processed.split()\n",
    "        \n",
    "        # Get word vectors\n",
    "        word_embeddings = []\n",
    "        for word in words:\n",
    "            if word in glove_embeddings:\n",
    "                word_embeddings.append(glove_embeddings[word])\n",
    "        \n",
    "        if len(word_embeddings) == 0:\n",
    "            return np.zeros(100)\n",
    "        \n",
    "        # Average the word vectors\n",
    "        return np.mean(word_embeddings, axis=0)\n",
    "\n",
    "    # Get embeddings for all rows\n",
    "    job_embeddings = []\n",
    "    for job_title in data['combined_string']:\n",
    "        embedding = get_document_embedding(job_title)\n",
    "        job_embeddings.append(embedding)\n",
    "    \n",
    "    # Get embedding for target string\n",
    "    target_embedding = get_document_embedding(target_string)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity(job_embeddings, [target_embedding]).flatten()\n",
    "    \n",
    "    return np.array(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2456efc9-9c36-4267-a63e-cb5dd7488a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_similarity(data, target_string):\n",
    "    \n",
    "    # Again, row embedding first\n",
    "    def get_document_embedding(text):\n",
    "        if pd.isna(text) or text == \"\":\n",
    "            return np.zeros(300)\n",
    "        \n",
    "        # Get row embedding\n",
    "        text_processed = preprocess_text(text)\n",
    "        words = text_processed.split()\n",
    "        \n",
    "        word_embeddings = []\n",
    "        for word in words:\n",
    "            if word in fasttext_embeddings:\n",
    "                word_embeddings.append(fasttext_embeddings[word])\n",
    "        \n",
    "        if len(word_embeddings) == 0:\n",
    "            return np.zeros(300)\n",
    "        return np.mean(word_embeddings, axis=0)\n",
    "        \n",
    "    # Get embeddings for all rows\n",
    "    job_embeddings = []\n",
    "    for job_title in data['combined_string']:\n",
    "        embedding = get_document_embedding(job_title)\n",
    "        job_embeddings.append(embedding)\n",
    "    \n",
    "    # Get embedding for target string\n",
    "    target_embedding = get_document_embedding(target_string)\n",
    "    \n",
    "    # Calculate similarities using cosine_similarity\n",
    "    similarities = cosine_similarity(job_embeddings, [target_embedding]).flatten()\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25d0e8da-b5b1-451e-849f-bff4568e8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT similarity\n",
    "\n",
    "def bert_similarity(data, target_string):\n",
    "    #Load BERT model and tokenizer\n",
    "    tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model=BertModel.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "\n",
    "    #Calculate BERT embeddings for job titles\n",
    "    doc_embeddings=[]\n",
    "    for text in data['combined_string']:\n",
    "        if pd.isna(text):\n",
    "            doc_embeddings.append(np.zeros(768))\n",
    "            continue\n",
    "\n",
    "        inputs=tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs=model(**inputs)\n",
    "            embedding=outputs.last_hidden_state[:,0,:].numpy().flatten()\n",
    "            doc_embeddings.append(embedding)\n",
    "\n",
    "    #Calculate BERT embedding for target\n",
    "    target_inputs=tokenizer(target_string, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        target_outputs=model(**target_inputs)\n",
    "        target_embedding=target_outputs.last_hidden_state[:,0,:].numpy().flatten()\n",
    "\n",
    "    #Calculate similarities\n",
    "    similarities=[]\n",
    "    for doc_embedding in doc_embeddings:\n",
    "        similarity=np.dot(doc_embedding, target_embedding) / (np.linalg.norm(doc_embedding) * np.linalg.norm(target_embedding) + 1e-8)\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    return np.array(similarities)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3078af39-7b77-4abb-ab79-ca9799a25a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And last, but not least SBERT\n",
    "\n",
    "def sbert_similarity(data, target_string):\n",
    "\n",
    "    #Load SBERT model\n",
    "    sbert_model=SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    #Get embeddings for job titles\n",
    "    job_titles=data['combined_string'].fillna('').tolist()\n",
    "    job_embeddings=sbert_model.encode(job_titles)\n",
    "\n",
    "    #get embedding for target\n",
    "    target_embedding = sbert_model.encode([target_string])\n",
    "\n",
    "    #Calculate similarities\n",
    "    similarities=cosine_similarity(job_embeddings, target_embedding).flatten()\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c587a3b-bd22-4089-a6d4-291e9cd42906",
   "metadata": {},
   "source": [
    "## Ranking and Reranking functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd4c2a-a86f-4a54-9435-1c34c3d91f26",
   "metadata": {},
   "source": [
    "Before moving to comparing our embedding methods, let's build functions for ranking and reranking our candidates based on a embedding method that was chosen. We'll try two different methods for reranking the starred candidates. But first let's build our main ranking function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6529bd7b-b144-4553-bece-ac6d179328de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking candidates first\n",
    "\n",
    "def rank_candidates(data, target_string, method='tfidf', starred_candidates=None, reranking_method='combining', connection_weight=0.1):\n",
    "    \"\"\"\n",
    "    method (str): Embedding method ('bow', 'tfidf', 'glove', 'fasttext','bert', 'sbert')\n",
    "    starred_candidates (list): List of candidate IDs that have been starred\n",
    "    reranking_method (str) : Reranking method ('combining', 'boosting') -- functions are provided below\n",
    "    \"\"\"\n",
    "    #Preprocessing the target string\n",
    "    target_processed=preprocess_text(target_string)\n",
    "\n",
    "    \n",
    "\n",
    "    # Calculate similarities based on method\n",
    "    if method == 'bow':\n",
    "        similarities=bag_of_words_similarity(data, target_processed)\n",
    "    elif method == 'tfidf':\n",
    "        similarities = tfidf_similarity(data, target_processed)\n",
    "    elif method == 'glove':\n",
    "        similarities = glove_similarity(data, target_string)\n",
    "    elif method == 'fasttext':\n",
    "        similarities = fasttext_similarity(data, target_string)\n",
    "    elif method == 'bert':\n",
    "        similarities = bert_similarity(data, target_string)  \n",
    "    elif method == 'sbert':\n",
    "        similarities = sbert_similarity(data, target_string)  \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Available methods: 'bow', 'tfidf', 'glove', 'fasttext','bert', 'sbert'\")\n",
    "\n",
    "    # Normalize similarities to 0-1 range\n",
    "    scaler=MinMaxScaler()\n",
    "    similarities_norm=scaler.fit_transform(similarities.reshape(-1,1)).flatten()\n",
    "\n",
    "    # Create ranking dataframe\n",
    "    ranking_df=data.copy()\n",
    "    ranking_df['similarity_score'] = similarities_norm\n",
    "    ranking_df['rank'] = ranking_df['similarity_score'].rank(ascending=False, method='min').astype(int)\n",
    "\n",
    "    # Apply re-ranking if starred candidates provided\n",
    "    if starred_candidates:\n",
    "        if reranking_method == 'boosting':\n",
    "            ranking_df=rerank_boosting(ranking_df, starred_candidates)\n",
    "        else:\n",
    "            if  method == 'bow':\n",
    "                ranking_df=rerank_combining(ranking_df, target_string, starred_candidates, embedding_func=bag_of_words_similarity)\n",
    "            elif method == 'tfidf':\n",
    "                ranking_df=rerank_combining(ranking_df, target_string, starred_candidates, embedding_func=tfidf_similarity)\n",
    "            elif method == 'glove':\n",
    "                ranking_df=rerank_combining(ranking_df, target_string, starred_candidates, embedding_func=glove_similarity)\n",
    "            elif method == 'fasttext':\n",
    "                ranking_df=rerank_combining(ranking_df, target_string, starred_candidates, embedding_func=fasttext_similarity)\n",
    "            elif method == 'bert':\n",
    "                ranking_df=rerank_combining(ranking_df, target_string, starred_candidates, embedding_func=bert_similarity)\n",
    "            elif method == 'sbert':\n",
    "                ranking_df=rerank_combining(ranking_df, target_string, starred_candidates, embedding_func=sbert_similarity)\n",
    "\n",
    "     # Adding a boost to the final similarity score based on the number of connections\n",
    "\n",
    "    # Cleaning the column first (converting to int)\n",
    "    def parse_connections(val):\n",
    "        if isinstance(val, str) and \"500\" in val:\n",
    "            return 500\n",
    "        try:\n",
    "            return int(val)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    connections = ranking_df['connection'].apply(parse_connections)\n",
    "    connections_norm = scaler.fit_transform(connections.to_numpy().reshape(-1,1)).flatten()\n",
    "    ranking_df['similarity_score'] += connection_weight * connections_norm\n",
    "\n",
    "    # Re-rank after adding connections\n",
    "    ranking_df['rank'] = ranking_df['similarity_score'].rank(ascending=False, method='min').astype(int)\n",
    "    \n",
    "    # Sort by rank\n",
    "    ranking_df=ranking_df.sort_values('rank').reset_index(drop=True)\n",
    "\n",
    "    return ranking_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8e512-4d6d-4c6e-96f6-d13ecab53a27",
   "metadata": {},
   "source": [
    "### Method 1 : Boosting score based on the similarity to starred candidates average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df4bd1-9c75-44d2-a355-34af9edc83df",
   "metadata": {},
   "source": [
    "First we'll try to calculate the average similarity score for our starred candidates and compare it to each candidate, giving them boosting scores based on the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b239c020-ec61-47f5-92d0-66acb8915988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_boosting(ranking_df, starred_candidates):\n",
    "\n",
    "    # Get features of starred candidates\n",
    "    starred_mask=ranking_df['id'].isin(starred_candidates)\n",
    "    starred_features=ranking_df[starred_mask]['similarity_score']\n",
    "\n",
    "    if len(starred_candidates) == 0:\n",
    "        return ranking_df\n",
    "\n",
    "    # Calculate average similarity of starred candidates\n",
    "    starred_avg = starred_features.mean()\n",
    "\n",
    "    # Boost scores for candidates similar to starred ones\n",
    "    for idx, row in ranking_df.iterrows():\n",
    "        candidate_score=row['similarity_score']\n",
    "\n",
    "        # Calculate similarity to starred candidates' average\n",
    "        similarity_to_starred=1-abs(candidate_score - starred_avg)\n",
    "\n",
    "        # Apply boost\n",
    "        boost_factor= 1 + 0.3 * similarity_to_starred\n",
    "        ranking_df.loc[idx, 'similarity_score'] = candidate_score * boost_factor\n",
    "\n",
    "    # Re-rank\n",
    "    ranking_df['rank']=ranking_df['similarity_score'].rank(ascending=False, method='min').astype(int)\n",
    "\n",
    "    return ranking_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e975a23-7679-4c39-b129-5c36feb401da",
   "metadata": {},
   "source": [
    "### Method 2 : Combining each candidates info with the starred candidates before calculating the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "624a8c9c-eace-455d-8eab-1f1e6ebe8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_combining(ranking_df, target_string, starred_candidates, embedding_func):\n",
    "\n",
    "    # Get features of starred candidates\n",
    "    starred_mask = ranking_df['id'].isin(starred_candidates)\n",
    "    starred_info = \" \".join(\n",
    "        ranking_df.loc[starred_mask, 'combined_string'].fillna(\"\").tolist()\n",
    "    )\n",
    "\n",
    "    # Create combined string for each candidate (candidate info string + starred info)\n",
    "    combined_strings = [\n",
    "        f\"{row['combined_string']} {starred_info}\" if pd.notna(row['combined_string']) else starred_info\n",
    "        for _, row in ranking_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Compute similarity using the combined string\n",
    "    temp_df = ranking_df.copy()\n",
    "    temp_df['job_title'] = combined_strings \n",
    "\n",
    "    similarities = embedding_func(temp_df, target_string)\n",
    "    temp_df['similarity_score'] = similarities\n",
    "\n",
    "    # Re-rank\n",
    "    temp_df['rank'] = temp_df['similarity_score'].rank(ascending=False, method='min').astype(int)\n",
    "\n",
    "\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b972cbbf-f22e-47b7-9f33-4bbb67ef7e61",
   "metadata": {},
   "source": [
    "## Comparing methods and choosing the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41156f83-53f3-4b8f-8db9-fb6632872e5c",
   "metadata": {},
   "source": [
    "Now we're ready to create functions for comparing our methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e28b191a-843c-45f0-acfd-2c86630d872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, comparing the methods\n",
    "def compare_methods(data, target_string, starred_candidates=None, reranking_method='combining'):\n",
    "    methods = ['bow', 'tfidf','glove', 'fasttext', 'bert', 'sbert']\n",
    "    results = {}\n",
    "\n",
    "    # Comparing methods for target\n",
    "    for method in methods:\n",
    "        try:\n",
    "            ranking=rank_candidates(data, target_string, method, starred_candidates, reranking_method=reranking_method)\n",
    "\n",
    "            # Store top 10 results\n",
    "            top10= ranking.head(10)[['rank', 'id', 'combined_string', 'similarity_score']]\n",
    "            results[method]={\n",
    "                'ranking': ranking,\n",
    "                'top_10': top10,\n",
    "                'avg_score': ranking['similarity_score'].mean(),\n",
    "                'max_score': ranking['similarity_score'].max()\n",
    "            }\n",
    "\n",
    "           # print top 5 candidates\n",
    "            if starred_candidates:\n",
    "                print(f\"Top 5 candidates using {method.upper()} embedding and {reranking_method.upper()} reranking method:\")\n",
    "            else:\n",
    "                print(f\"Top 5 candidates using {method.upper()} embedding:\")\n",
    "            for _, row in top10.head(5).iterrows():\n",
    "                starred_mark = \" ⭐\" if row['id'] in (starred_candidates or []) else \"\"\n",
    "                print(f\"  {row['rank']:2d}. ID {row['id']:3d} - {row['combined_string'][:50]:<50} (Score: {row['similarity_score']:.4f}){starred_mark}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {method}: {e}\")\n",
    "            continue\n",
    "    return results\n",
    "\n",
    "# Now let's get the best method\n",
    "def get_best_method(data, target_string, starred_candidates=None, reranking_method='combining'):\n",
    "    results=compare_methods(data, target_string, starred_candidates=starred_candidates, reranking_method=reranking_method)\n",
    "\n",
    "    #Find method with highest average score\n",
    "    best_method = max(results.keys(), key=lambda x:results[x]['avg_score'])\n",
    "\n",
    "    print(f\"Best Method : {best_method}\")\n",
    "    print(f\"Average similarity score : {results[best_method]['avg_score']:.4f}\")\n",
    "\n",
    "    return best_method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84dd259-94d1-473a-a962-e15c7d5ad738",
   "metadata": {},
   "source": [
    "Now let's test our function, first without starred candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc493ded-8ab2-444c-ad72-8b9cbfa9dc33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 candidates using BOW embedding:\n",
      "   1. ID  28 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.0780)\n",
      "   1. ID  30 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.0780)\n",
      "   3. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9044)\n",
      "   3. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9044)\n",
      "   3. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9044)\n",
      "Top 5 candidates using TFIDF embedding:\n",
      "   1. ID  28 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.0780)\n",
      "   1. ID  30 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.0780)\n",
      "   3. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9660)\n",
      "   3. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9660)\n",
      "   3. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9660)\n",
      "Top 5 candidates using GLOVE embedding:\n",
      "   1. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.0902)\n",
      "   1. ID  62 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.0902)\n",
      "   1. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.0902)\n",
      "   1. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.0902)\n",
      "   5. ID  94 - Seeking Human  Resources Opportunities. Open to tr (Score: 1.0723)\n",
      "Top 5 candidates using FASTTEXT embedding:\n",
      "   1. ID  78 - Human Resources Generalist at Schwan's Amerika Bir (Score: 1.1000)\n",
      "   2. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9559)\n",
      "   2. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9559)\n",
      "   2. ID  62 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9559)\n",
      "   2. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9559)\n",
      "Top 5 candidates using BERT embedding:\n",
      "   1. ID  28 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.0402)\n",
      "   1. ID  30 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.0402)\n",
      "   3. ID   8 - HR Senior Specialist San Francisco Bay Area        (Score: 1.0259)\n",
      "   3. ID  26 - HR Senior Specialist San Francisco Bay Area        (Score: 1.0259)\n",
      "   3. ID  51 - HR Senior Specialist San Francisco Bay Area        (Score: 1.0259)\n",
      "Top 5 candidates using SBERT embedding:\n",
      "   1. ID 101 - Human Resources Generalist at Loparex Raleigh-Durh (Score: 1.0259)\n",
      "   2. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.0235)\n",
      "   2. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.0235)\n",
      "   2. ID  62 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.0235)\n",
      "   2. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.0235)\n",
      "Best Method : bert\n",
      "Average similarity score : 0.6585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bert'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_string = \"seeking human resources\"\n",
    "get_best_method(data, target_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65558e0-5026-4bc1-8746-15ab82ea63c4",
   "metadata": {},
   "source": [
    "Now let's add some starred candidates and use the 'boosting' reranking method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "811c1bdf-751e-40ee-a84b-9cf010c66d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 candidates using BOW embedding and BOOSTING reranking method:\n",
      "   1. ID  28 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.3067) ⭐\n",
      "   1. ID  30 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.3067)\n",
      "   3. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.1356)\n",
      "   3. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.1356)\n",
      "   3. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.1356) ⭐\n",
      "Top 5 candidates using TFIDF embedding and BOOSTING reranking method:\n",
      "   1. ID  28 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.2870) ⭐\n",
      "   1. ID  30 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.2870)\n",
      "   3. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.1819)\n",
      "   3. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.1819)\n",
      "   3. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.1819) ⭐\n",
      "Top 5 candidates using GLOVE embedding and BOOSTING reranking method:\n",
      "   1. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.3729)\n",
      "   1. ID  62 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.3729)\n",
      "   1. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.3729) ⭐\n",
      "   1. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.3729)\n",
      "   5. ID  94 - Seeking Human  Resources Opportunities. Open to tr (Score: 1.3550)\n",
      "Top 5 candidates using FASTTEXT embedding and BOOSTING reranking method:\n",
      "   1. ID  78 - Human Resources Generalist at Schwan's Amerika Bir (Score: 1.3216)\n",
      "   2. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.1826)\n",
      "   2. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.1826) ⭐\n",
      "   2. ID  62 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.1826)\n",
      "   2. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.1826)\n",
      "Top 5 candidates using BERT embedding and BOOSTING reranking method:\n",
      "   1. ID  28 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.2771) ⭐\n",
      "   1. ID  30 - Seeking Human Resources Opportunities Chicago, Ill (Score: 1.2771)\n",
      "   3. ID   8 - HR Senior Specialist San Francisco Bay Area        (Score: 1.2640)\n",
      "   3. ID  26 - HR Senior Specialist San Francisco Bay Area        (Score: 1.2640)\n",
      "   3. ID  51 - HR Senior Specialist San Francisco Bay Area        (Score: 1.2640)\n",
      "Top 5 candidates using SBERT embedding and BOOSTING reranking method:\n",
      "   1. ID 101 - Human Resources Generalist at Loparex Raleigh-Durh (Score: 1.2913)\n",
      "   2. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.2889)\n",
      "   2. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.2889) ⭐\n",
      "   2. ID  62 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.2889)\n",
      "   2. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 1.2889)\n",
      "Best Method : bert\n",
      "Average similarity score : 0.8109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bert'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_string = \"seeking human resources\"\n",
    "starred_candidates=[53, 28, 68]\n",
    "\n",
    "get_best_method(data, target_string, starred_candidates=starred_candidates, reranking_method='boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9b4e1-79ee-4916-a537-9e60c9682912",
   "metadata": {},
   "source": [
    "And lastly let's try 'combining' reranking method with the same list of starred candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b089f3c-a68d-4809-833a-29ef48f1bb83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 candidates using BOW embedding and COMBINING reranking method:\n",
      "   1. ID  28 - Seeking Human Resources Opportunities Chicago, Ill (Score: 0.4825) ⭐\n",
      "   1. ID  30 - Seeking Human Resources Opportunities Chicago, Ill (Score: 0.4825)\n",
      "   3. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.4254)\n",
      "   3. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.4254)\n",
      "   3. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.4254) ⭐\n",
      "Top 5 candidates using TFIDF embedding and COMBINING reranking method:\n",
      "   1. ID  28 - Seeking Human Resources Opportunities Chicago, Ill (Score: 0.2903) ⭐\n",
      "   1. ID  30 - Seeking Human Resources Opportunities Chicago, Ill (Score: 0.2903)\n",
      "   3. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.2839)\n",
      "   3. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.2839)\n",
      "   3. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.2839) ⭐\n",
      "Top 5 candidates using GLOVE embedding and COMBINING reranking method:\n",
      "   1. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9776)\n",
      "   1. ID  62 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9776)\n",
      "   1. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9776) ⭐\n",
      "   1. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.9776)\n",
      "   5. ID  94 - Seeking Human  Resources Opportunities. Open to tr (Score: 0.9602)\n",
      "Top 5 candidates using FASTTEXT embedding and COMBINING reranking method:\n",
      "   1. ID  78 - Human Resources Generalist at Schwan's Amerika Bir (Score: 0.9858)\n",
      "   2. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.8892)\n",
      "   2. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.8892) ⭐\n",
      "   2. ID  62 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.8892)\n",
      "   2. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.8892)\n",
      "Top 5 candidates using BERT embedding and COMBINING reranking method:\n",
      "   1. ID   8 - HR Senior Specialist San Francisco Bay Area Seekin (Score: 0.9782)\n",
      "   1. ID  26 - HR Senior Specialist San Francisco Bay Area Seekin (Score: 0.9782)\n",
      "   1. ID  51 - HR Senior Specialist San Francisco Bay Area Seekin (Score: 0.9782)\n",
      "   1. ID  38 - HR Senior Specialist San Francisco Bay Area Seekin (Score: 0.9782)\n",
      "   1. ID  61 - HR Senior Specialist San Francisco Bay Area Seekin (Score: 0.9782)\n",
      "Top 5 candidates using SBERT embedding and COMBINING reranking method:\n",
      "   1. ID 101 - Human Resources Generalist at Loparex Raleigh-Durh (Score: 0.8337)\n",
      "   2. ID  10 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.8321)\n",
      "   2. ID  53 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.8321) ⭐\n",
      "   2. ID  62 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.8321)\n",
      "   2. ID  40 - Seeking Human Resources HRIS and Generalist Positi (Score: 0.8321)\n",
      "Best Method : bert\n",
      "Average similarity score : 0.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bert'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starred_candidates=[53, 28, 68]\n",
    "get_best_method(data, target_string, starred_candidates=starred_candidates, reranking_method='combining')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01faed7d-2058-464f-b845-c6dc2546d51e",
   "metadata": {},
   "source": [
    "It looks like the only embedding method that shows different results based on the reranking method is BERT. Others show the same results and include at least one starred candidate in the final top 5 results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
